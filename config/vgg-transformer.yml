vocab: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~ '

device: cpu
    
pretrain: 
    id_or_url: 12dTOZ9VP7ZVzwQgVvqBWz5JO5RXXW5NY
    md5: 1cc2bb91d3ef1fb596eb13794d56ea1e
    cached: /tmp/tranformerorc.pth

weights: https://drive.google.com/uc?id=12dTOZ9VP7ZVzwQgVvqBWz5JO5RXXW5NY

backbone: vgg
cnn:
    pooling_stride_size:
        - [2, 2]
        - [2, 1]
        - [2, 1]
        - [2, 1]
        - [1, 1]          
    pooling_kernel_size:
        - [2, 2]
        - [2, 2]
        - [1, 1]
        - [1, 1]
        - [1, 1]
    
transformer:    
    d_model: 512
    nhead: 8
    num_encoder_layers: 6
    num_decoder_layers: 6
    dim_feedforward: 2048
    max_seq_length: 10000
    pos_dropout: 0.1
    trans_dropout: 0.1

optimizer:
    n_warmup_steps: 4000

trainer:
    batch_size: 32
    print_every: 200
    valid_every: 4000
    epochs: 10
    export: ./weights/transformerocr.pth
    checkpoint: ./checkpoint/transformerocr_checkpoint.pth
    data_root: ./img/
    train_annotation: annotation_train.txt
    valid_annotation: annotation_val_small.txt
    log: ./train.log
    metrics: null
 
quiet: False 
